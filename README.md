#  Sign Language Detection using YOLOv11 (Update (November 2025): Verified code compatibility with the latest PyTorch and Ultralytics YOLOv11 release.)

<div align="center">
  <img src="https://media.giphy.com/media/r4N5NIckk37x76byEf/giphy.gif?cid=790b76114q7ujlpguzc2zydj63z6ftf1al6yelf52rzgmc9p&ep=v1_gifs_search&rid=giphy.gif&ct=g" alt="Sign Language Detection Demo" width="700"/>
  <p><i>Real-time sign language detection powered by YOLOv11</i></p>
</div>

## ğŸŒŸ Journey & Challenges Overcome

> "Every error message was a stepping stone to success"

- ğŸ”¥ Exhausted 2 Google Colab accounts' RAM
- ğŸ’ª Persisted through numerous dependency conflicts
- ğŸ§¹ Cleared precious storage space, sacrificing other applications
- ğŸ› Tackled and resolved countless bugs
- ğŸš€ Never gave up despite the obstacles!

## âœ¨ Features

- ğŸ¯ Real-time sign language detection
- ğŸ¤– Powered by YOLOv11 architecture
- ğŸ“Š High accuracy detection
- ğŸ® User-friendly interface
- ğŸš€ GPU-accelerated inference (If you have colab pro you can use A100 GPU otherwise T4 GPU)
- ğŸ”„ Support for multiple hand gestures

## ğŸ¬ Demo & Results (Click on the image below to watch the Demo)

<div align="center">
  <a href="https://youtu.be/tuEgzAvdPyg?si=-S1FawDs3KQtWgLV">
    <img src="https://raw.githubusercontent.com/azaynul10/sign-language-detection-yolov11/main/how%20to%20always%20stay%20(1).png" alt="Sign Language Detection Demo" width="600"/>
  </a>
  <p><i>Real-time sign language detection demonstrating "Hello", "Thank You", "Yes" , "No" and "I Love You" gestures</i></p>
</div>

## ğŸ› ï¸ Technical Details

```python
# Core Technologies
- YOLOv11
- TensorFlow
- OpenCV
- Python
- CUDA for GPU acceleration
```

# ğŸ“Š Model Performance

## Detection Results
| Gesture    | Confidence Score | Detection Time |
|------------|-----------------|----------------|
| Hello      | 95%             | ~8.4ms        |
| Thank You  | 92%             | ~7.2ms        |
| Love You   | 93%             | ~7.8ms        |

## Key Metrics
- **Average Inference Time**: 7.8ms per frame
- **FPS**: ~128 frames per second
- **Input Resolution**: 640x640 pixels
- **Model Architecture**: YOLOv11
- **Hardware**: Google Colab T4 GPU

## Performance by Gesture
### Hello
- âœ… High accuracy in frontal hand detection
- âœ… Consistent detection with varying hand positions
- âš ï¸ May need improvement in low-light conditions

### Thank You
- âœ… Good detection of folded hands
- âœ… Works well with different angles
- âš ï¸ Occasional confusion with similar gestures

### Love You
- âœ… Accurate detection of the specific hand shape
- âœ… Robust against different backgrounds
- âš ï¸ May require more training data for edge cases

## Training Statistics
- **Training Duration**: XX hours
- **Number of Epochs**: 50
- **Training Dataset Size**: XX images (I've used less amount of datasets but I would suggest you create datasets using my tutorial file and annotate them in .yml files for YOLO v11 or get datasets from RoboFlow and train with your own datasets)
- **Validation Dataset Size**: XX images
- **Hardware Used**: Google Colab T4 GPU

## Challenges Overcome
- ğŸ”„ RAM limitations on Google Colab
- ğŸ’¾ Storage constraints
- ğŸ› Dependency conflicts

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/azaynul10/sign-language-detection-yolov11

```
You can then run it in your Google Colab.
## ğŸ’ª Challenges & Solutions

<details>
<summary>Click to expand!</summary>

- **RAM Limitations**: 
  - Optimized batch sizes
  - Implemented gradient checkpointing
  
- **Storage Issues**: 
  - Streamlined dataset management
  - Optimized model checkpoints
  
- **Dependency Conflicts**: 
  - Created detailed environment setup
  - Documented working configurations
</details>

## ğŸ“ˆ Training Process

<div align="center">
  <img src="https://github.com/user-attachments/assets/8f1da8bc-e9ee-4ab2-9ddd-37f8ac6a15b3" alt="Training Metrics" width="600"/>
</div>

## ğŸ¤ Contributing

Contributions are welcome! Feel free to:
- ğŸ› Report bugs
- ğŸ’¡ Suggest features
- ğŸ”§ Submit PRs

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---
<div align="center">
  <b>Built with persistence, powered by determination! ğŸ’ª</b>
  
  If you found this helpful, please â­ this repository!
</div>
